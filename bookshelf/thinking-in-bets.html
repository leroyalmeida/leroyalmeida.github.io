<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Leroy's Notes on Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts</title>

    <meta name="description" content="Thinking in bets starts with recognizing that there are exactly two things that determine how our lives turn out: the quality of our decisions and luck. Learning to recognize the difference between the two is what thinking in bets is all about.">
    <meta name="keywords" content="Leroy, Almeida, Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts, summary, review, Book recommendations, Portfolio, Designer, User Experience, UX, UI, Visual, Product Designer, Manila, Philippines, Strategy, Mobile, Web, Interface, Design, Mobile Design, Web Design, Interface Design, Interaction Design, Design Strategy, Web application, Application, TV, Device, Product, Internet, Software, Expert, Usability, Information Architecture, Redesign, Mockups">
    <meta name="robots" content="index,follow">
    <link rel="canonical" href="https://leroyalmeida.com/bookshelf/thinking-in-bets" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" />

    <!-- Open Graph -->
    <meta property="og:title" content="Leroy's Notes on Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts" />
    <meta property="og:url" content="https://leroyalmeida.com/bookshelf/thinking-in-bets" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="Thinking in bets starts with recognizing that there are exactly two things that determine how our lives turn out: the quality of our decisions and luck. Learning to recognize the difference between the two is what thinking in bets is all about.">
    <meta property="og:image" content="https://leroyalmeida.com/images/covers/thinking-in-bets.jpg">

    <!-- Twitter Cards -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Leroy's Notes on Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts" />
    <meta name="twitter:description" content="Thinking in bets starts with recognizing that there are exactly two things that determine how our lives turn out: the quality of our decisions and luck. Learning to recognize the difference between the two is what thinking in bets is all about.">
    <meta name="twitter:site" content="@leroyalmeida23">
    <meta name="twitter:image" content="https://leroyalmeida.com/images/covers/thinking-in-bets.jpg">

    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-122663238-1', 'auto');
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->

    <!-- favicon and apple icons -->
    <link rel="icon" href="/images/icons/favicon.ico">
    <link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png">

    <!-- link to html stylesheet -->
    <link rel="stylesheet" type="text/css" href="/css/stylesheets/normalize.css">
    <link rel="stylesheet" type="text/css" href="/css/stylesheets/skeleton.css">
    <link rel="stylesheet" type="text/css" href="/css/stylesheets/custom.css">

  </head>
  <body>
      <div class="container">
        <div class="three columns">
          <nav>
            <h2 id="logo" >
              <a href="/">Leroy Almeida</a>
            </h2>
            <ul>
              <li><a href="/work">Work</a></li>
              <li><a href="/bookshelf">Bookshelf</a></li>
              <li><a href="https://twitter.com/leroyalmeida23">Twitter</a></li>
              <li><a href="https://www.linkedin.com/in/leroyalmeida/">LinkedIn</a></li>
            </ul>
          </nav>
          &nbsp;
        </div>
        <div class="eight columns offset-by-one">
          <h1>Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts</h1>
          <div class="book-details">
            <div class="book-image">
              <img
                  class="scale-with-grid page-image"
                  src="/images/covers/thinking-in-bets.jpg"
                  width="160"
                  height="240"
                  layout="responsive"
                  alt="">
              </img>
            </div>
            <div class="details">
              <table>
                <tbody>
                <!-- <tr class="detail">
                  <td class="detail-category">Title:</td>
                  <td class="detail-content">Thinking in Bets: Making Smarter Decisions When You Don't Have All the Facts</td>
                </tr> -->
                <tr class="detail">
                  <td class="detail-category">Author:</td>
                  <td class="detail-content">Annie Duke</td>
                </tr>
                <tr class="detail">
                  <td class="detail-category">Year Read:</td>
                  <td class="detail-content">2020</td>
                </tr>
                <!-- <tr class="detail">
                  <td class="detail-category">Buy This Book:</td>
                  <td class="detail-content"><a href="thinking-in-bets" target="_blank">Amazon</a></td>
                </tr> -->
                <tr class="detail">
                  <td class="detail-category">Summary</td>
                  <td class="detail-content">Thinking in bets starts with recognizing that there are exactly two things that determine how our lives turn out: the quality of our decisions and luck. Learning to recognize the difference between the two is what thinking in bets is all about.</td>
                </tr>
              </tbody></table>
            </div>
            <div class="clearfix"></div>
          </div>
          <h4>Key Takeaways:</h4>
          <ul>
            <li><div>INTRODUCTION: Why This Isn’t a Poker Book</div></li><ul><li><div>What a bet really is: a decision about an uncertain future.<br></div></li><li><div><strong>Thinking in bets starts with recognizing that there are exactly two things that determine how our lives turn out: the quality of our decisions and luck. Learning to recognize the difference between the two is what thinking in bets is all about.</strong><br></div></li></ul><li><div>CHAPTER 1: Life Is Poker, Not Chess</div></li><ul><li><div>Pete Carroll and the Monday Morning Quarterbacks<br></div></li><ul><li><div><strong>Our tendency to equate the quality of a decision with the quality of its outcome. Poker players have a word for this: “resulting.”</strong><br></div></li></ul><li><div>The hazards of resulting<br></div></li><ul><li><div><strong>Hindsight bias is the tendency, after an outcome is known, to see the outcome as having been inevitable.</strong><br></div></li></ul><li><div>Quick or dead: our brains weren’t built for rationality<br></div></li><ul><li><div>Incorrectly interpreting rustling from the wind as an oncoming lion is called a type I error, a false positive. The consequences of such an error were much less grave than those of a type II error, a false negative.</div></li><li><div>System 1 as “fast thinking.” System 1 is what causes you to hit the brakes the instant someone jumps into the street in front of your car. It encompasses reflex, instinct, intuition, impulse, and automatic processing. System 2, “slow thinking,” is how we choose, concentrate, and expend mental energy.</div></li><li><div>Automatic processing originates in the evolutionarily older parts of the brain, including the cerebellum, basal ganglia, and amygdala. Our deliberative mind operates out of the prefrontal cortex.</div></li><li><div>Making more rational decisions isn’t just a matter of willpower or consciously handling more decisions in deliberative mind. Our deliberative capacity is already maxed out.</div></li><li><div><strong>The challenge is not to change the way our brains operate but to figure out how to work within the limitations of the brains we already have. Being aware of our irrational behavior and wanting to change is not enough.</strong></div></li></ul><li><div>Two-minute warning</div></li><ul><li><div><strong>Our goal is to get our reflexive minds to execute on our deliberative minds’ best intentions.</strong></div></li><li><div>Poker players, as a result, must become adept at in-the-moment decision-making or they won’t survive in the profession. That means finding ways to execute their best intentions (deliberated in advance) within the constraints of the speed expected at the table. Making a living at poker requires interpolating between the deliberative and reflexive systems. The best players must find ways to harmonize otherwise irresolvable conflicts.</div></li><li><div>In addition, once the game is over, poker players must learn from that jumbled mass of decisions and outcomes, separating the luck from the skill, the signal from the noise, and guarding against resulting.</div></li></ul><li><div>Dr. Strangelove</div></li><ul><li><div>John von Neumann is also the father of game theory. After finishing his day job on the Manhattan Project, he collaborated with Oskar Morgenstern to publish Theory of Games and Economic Behavior in 1944.</div></li><li><div>The Boston Public Library’s list of the “100 Most Influential Books of the Century” includes Theory of Games. William Poundstone, author of a widely read book on game theory, Prisoner’s Dilemma, called it “one of the most influential and least-read books of the twentieth century.”</div></li><li><div>Game theory was succinctly defined by economist Roger Myerson (one of the game-theory Nobel laureates) as “the study of mathematical models of conflict and cooperation between intelligent rational decision-makers.”</div></li><li><div>John von Neumann modeled game theory on a stripped-down version of poker.</div></li></ul><li><div>Poker vs. chess</div></li><ul><li><div>Poker, in contrast, is a game of incomplete information. It is a game of decision-making under conditions of uncertainty over time.</div></li><li><div>There is also an element of luck in any outcome. You could make the best possible decision at every point and still lose the hand, because you don’t know what new cards will be dealt and revealed. Once the game is finished and you try to learn from the results, separating the quality of your decisions from the influence of luck is difficult.</div></li><li><div>In chess, outcomes correlate more tightly with decision quality. In poker, it is much easier to get lucky and win, or get unlucky and lose.</div></li><li><div><strong>Incomplete information poses a challenge not just for split-second decision-making, but also for learning from past decisions.</strong></div></li><li><div><strong>If we want to improve in any game—as well as in any aspect of our lives—we have to learn from the results of our decisions. The quality of our lives is the sum of decision quality plus luck.</strong></div></li><li><div>Resulting, assuming that our decision-making is good or bad based on a small set of outcomes, is a pretty reasonable strategy for learning in chess. But not in poker—or life.</div></li></ul><li><div>A lethal battle of wits</div></li><ul><li><div>Our lives are too short to collect enough data from our own experience to make it easy to dig down into decision quality from the small set of results we experience.</div></li></ul><li><div>“I’m not sure”: using uncertainty to our advantage</div></li><ul><li><div>getting comfortable with “I’m not sure” is a vital step to being a better decision-maker. We have to make peace with not knowing.</div></li><li><div>Of course, we want to encourage acquiring knowledge, but the first step is understanding what we don’t know.</div></li><li><div>“I don’t know” is not a failure but a necessary step toward enlightenment.</div></li><li><div>What makes a decision great is not that it has a great outcome. A great decision is the result of a good process, and that process must include an attempt to accurately represent our own state of knowledge.</div></li><li><div>“I’m not sure” does not mean that there is no objective truth. Firestein’s point is, in fact, that acknowledging uncertainty is the first step in executing on our goal to get closer to what is objectively true.</div></li><li><div>What good poker players and good decision-makers have in common is their comfort with the world being an uncertain and unpredictable place. They understand that they can almost never know exactly how something will turn out. They embrace that uncertainty and, instead of focusing on being sure, they try to figure out how unsure they are, making their best guess at the chances that different outcomes will occur.</div></li><li><div>An expert in any field will have an advantage over a rookie. But neither the veteran nor the rookie can be sure what the next flip will look like. The veteran will just have a better guess.</div></li><li><div>when we accept that we can’t be sure, we are less likely to fall into the trap of black-and-white thinking.</div></li></ul><li><div>Redefining wrong</div></li><ul><li><div>When we think in advance about the chances of alternative outcomes and make a decision based on those chances, it doesn’t automatically make us wrong when things don’t work out. It just means that one event in a set of possible futures occurred.</div></li><li><div>Any prediction that is not 0% or 100% can’t be wrong solely because the most likely future doesn’t unfold.</div></li><li><div>Long shots hit some of the time. Blaming the oddsmakers or the odds themselves assumes that once something happens, it was bound to have happened and anyone who didn’t see it coming was wrong.</div></li><li><div>Decisions are bets on the future, and they aren’t “right” or “wrong” based on whether they turn out well on any particular iteration.</div></li><li><div>When we think probabilistically, we are less likely to use adverse results alone as proof that we made a decision error, because we recognize the possibility that the decision might have been good but luck and/or incomplete information (and a sample size of one) intervened.</div></li><li><div>Redefining wrong is easiest in situations where we know the mathematical facts in advance.</div></li><li><div>Redefining wrong allows us to let go of all the anguish that comes from getting a bad result. But it also means we must redefine “right.”</div></li><li><div>The influence of luck makes it impossible to predict exactly how things will turn out, and all the hidden information makes it even worse.</div></li></ul></ul><li><div>CHAPTER 2: Wanna Bet?</div></li><ul><li><div>Thirty days in Des Moines</div></li><ul><li><div><strong>Every decision has risks, regardless of whether we acknowledge them.</strong></div></li><li><div>In addition, whenever we choose an alternative (whether it is taking a new job or moving to Des Moines for a month), we are automatically rejecting every other possible choice. All those rejected alternatives are paths to possible futures where things could be better or worse than the path we chose. There is potential opportunity cost in any choice we forgo.</div></li><li><div>Although employers aren’t trying to entice employees to quit, their goal is similar in arriving at a compensation package to get the prospect to accept the offer and stay in the job. They must balance offering attractive pay and benefits with going too far and impairing their ability to make a profit. — Relevant to me because I feel that the last pay raise I was given was high enough to be considered a raise, but mostly I think it was done to remove my overtime pay benefits, because I was “upgraded” to the next pay band. Without the overtime pay benefits, I actually earn less.</div></li><li><div>Hiring an employee, like offering a bet, is not a riskless choice. Betting on hiring the wrong person can have a huge cost (as the CEO who fired his president can attest). Recruitment costs can be substantial, and every job offer has an associated opportunity cost.</div></li></ul><li><div><strong>All decisions are bets</strong></div></li><ul><li><div>Merriam-Webster’s Online Dictionary defines “bet” as “a choice made by thinking about what will probably happen,” “to risk losing (something) when you try to do or achieve something” and “to make decisions that are based on the belief that something will happen or is true.”</div></li><li><div>We routinely decide among alternatives, put resources at risk, assess the likelihood of different outcomes, and consider what it is that we value. Every decision commits us to some course of action that, by definition, eliminates acting on other alternatives.</div></li></ul><li><div>Most bets are bets against ourselves</div></li><ul><li><div><strong>In most of our decisions, we are not betting against another person. Rather, we are betting against all the future versions of ourselves that we are not choosing.</strong></div></li><li><div>At stake in a decision is that the return to us (measured in money, time, happiness, health, or whatever we value in that circumstance) will be greater than what we are giving up by betting against the other alternative future versions of us.</div></li><li><div>How can we be sure that we are choosing the alternative that is best for us? What if another alternative would bring us more happiness, satisfaction, or money? The answer, of course, is we can’t be sure. Things outside our control (luck) can influence the result. The futures we imagine are merely possible. They haven’t happened yet. We can only make our best guess, given what we know and don’t know, at what the future will look like.</div></li></ul><li><div><strong>Our bets are only as good as our beliefs</strong></div></li><ul><li><div><strong>Our beliefs drive the bets we make</strong>: which brands of cars better retain their value, whether critics knew what they were talking about when they panned a movie we are thinking about seeing, how our employees will behave if we let them work from home.</div></li><li><div><strong>Part of the skill in life comes from learning to be a better belief calibrator, using experience and information to more objectively update our beliefs to more accurately represent the world. </strong></div></li><ul><li><div><strong>The more accurate our beliefs, the better the foundation of the bets we make.</strong></div></li></ul></ul><li><div>Hearing is believing</div></li><ul><li><div>This is how we think we form abstract beliefs:</div></li><ul><li><div>We hear something;</div></li><li><div>We think about it and vet it, determining whether it is true or false; only after that</div></li><li><div>We form our belief.</div></li><li><div>It turns out, though, that we actually form abstract beliefs this way:</div></li><li><div>We hear something;</div></li><li><div>We believe it to be true;</div></li><li><div>Only sometimes, later, if we have the time or the inclination, we think about it and vet it, determining whether it is, in fact, true or false.</div></li></ul><li><div>Gilbert and colleagues demonstrated through a series of experiments that our default is to believe that what we hear and read is true. Even when that information is clearly presented as being false, we are still likely to process it as true.</div></li><li><div><strong>As with many of our irrationalities, how we form beliefs was shaped by the evolutionary push toward efficiency rather than accuracy.</strong></div></li><li><div>Instead of altering our beliefs to fit new information, we do the opposite, altering our interpretation of that information to fit our beliefs.</div></li></ul><li><div>“They saw a game”</div></li><ul><li><div>“We do not simply ‘react to’ a happening.&nbsp;.&nbsp;.&nbsp;. We behave according to what we bring to the occasion.” Our beliefs affect how we process all new things, “whether the ‘thing’ is a football game, a presidential candidate, Communism, or spinach.”</div></li><li><div>Whether it is a football game, a protest, or just about anything else, our pre-existing beliefs influence the way we experience the world.</div></li></ul><li><div>The stubbornness of beliefs</div></li><ul><li><div><strong>Once a belief is lodged, it becomes difficult to dislodge.</strong> It takes on a life of its own, leading us to notice and <strong>seek out evidence confirming our belief</strong>, rarely challenge the validity of confirming evidence, and <strong>ignore or work hard to actively discredit information contradicting the belief</strong>. This irrational, circular information-processing pattern is called <strong>motivated reasoning</strong>. The way we process new information is driven by the beliefs we hold, strengthening them. Those strengthened beliefs then drive how we process further information, and so on.</div></li><li><div>Disinformation is different than fake news in that the story has some true elements, embellished to spin a particular narrative. Fake news works because people who already hold beliefs consistent with the story generally won’t question the evidence. Disinformation is even more powerful because the confirmable facts in the story make it feel like the information has been vetted, adding to the power of the narrative being pushed.</div></li><li><div>Fake news isn’t meant to change minds. As we know, beliefs are hard to change. The potency of fake news is that it entrenches beliefs its intended audience already has, and then amplifies them.</div></li></ul><li><div>Being smart makes it worse</div></li><ul><li><div><strong>The smarter you are, the better you are at constructing a narrative that supports your beliefs, rationalizing and framing the data to fit your argument or point of view.</strong></div></li><li><div>Blind-spot bias—an irrationality where people are better at recognizing biased reasoning in others but are blind to bias in themselves.</div></li><li><div><strong>Blind-spot bias is greater the smarter you are.</strong></div></li><li><div>“Furthermore, people who were aware of their own biases were not better able to overcome them.” In fact, in six of the seven biases tested, “more cognitively sophisticated participants showed larger bias blind spots.”</div></li><li><div>The more numerate people (whether pro- or anti-gun) made more mistakes interpreting the data on the emotionally charged topic than the less numerate subjects sharing those same beliefs. “This pattern of polarization&nbsp;.&nbsp;.&nbsp;. does not abate among high-Numeracy subjects. Indeed, it increases.”</div></li><li><div>It turns out the better you are with numbers, the better you are at spinning those numbers to conform to and support your beliefs.</div></li></ul><li><div>Wanna bet?</div></li><ul><li><div>Being asked if we are willing to bet money on it makes it much more likely that we will examine our information in a less biased way, be more honest with ourselves about how sure we are of our beliefs, and be more open to updating and calibrating our beliefs.</div></li><li><div><strong>The more objective we are, the more accurate our beliefs become.</strong></div></li><li><div>Offering a wager brings the risk out in the open, making explicit what is already implicit (and frequently overlooked).</div></li></ul><li><div>Redefining confidence</div></li><ul><li><div>What if, in addition to expressing what we believe, we also rated our level of confidence about the accuracy of our belief on a scale of zero to ten?</div></li><li><div><strong>Forcing ourselves to express how sure we are of our beliefs brings to plain sight the probabilistic nature of those beliefs, that what we believe is almost never 100% or 0% accurate but, rather, somewhere in between.</strong></div></li><li><div>In a similar vein, the number can reflect several different kinds of uncertainty.</div></li><li><div>Our knowledge of this past event is incomplete.</div></li></ul></ul><ul><ul><li><div><strong>We can also express how confident we are by thinking about the number of plausible alternatives and declaring that range.</strong></div></li><li><div><strong>The more we know about a topic, the better the quality of information we have, the tighter the range of plausible alternatives.</strong> (When it comes to predictions, the plausible range of outcomes would also be tighter when there is less luck involved.) The less we know about a topic or the more luck involved, the wider our range.</div></li><li><div>Incorporating uncertainty into the way we think about our beliefs comes with many benefits. By expressing our level of confidence in what we believe, we are shifting our approach to how we view the world.</div></li><li><div><strong>Acknowledging uncertainty is the first step in measuring and narrowing it.</strong> Incorporating uncertainty in the way we think about what we believe creates open-mindedness, moving us closer to a more objective stance toward information that disagrees with us.</div></li><li><div><strong>When we work toward belief calibration, we become less judgmental of ourselves.</strong> Incorporating percentages or ranges of alternatives into the expression of our beliefs means that our personal narrative no longer hinges on whether we were wrong or right but on how well we incorporate new information to adjust the estimate of how accurate our beliefs are.</div></li><li><div>Admitting we are not sure is an invitation for help in refining our beliefs, and that will make our beliefs much more accurate over time as we are more likely to gather relevant information.</div></li><li><div>When scientists publish results of experiments, they share with the rest of their community their methods of gathering and analyzing the data, the data itself, and their confidence in that data. That makes it possible for others to assess the quality of the information being presented, systematized through peer review before publication.</div></li></ul></ul><li><div>CHAPTER 3: Bet to Learn: Fielding the Unfolding Future</div></li><ul><li><div>Nick the Greek, and other lessons from the Crystal Lounge</div></li><ul><li><div><strong>While experience is necessary to becoming an expert, it’s not sufficient.</strong></div></li></ul><li><div>Outcomes are feedback</div></li><ul><li><div>As novelist and philosopher Aldous Huxley recognized, <strong>“Experience is not what happens to a man; it is what a man does with what happens to him.”</strong></div></li><li><div>There is a big difference between getting experience and becoming an expert. That difference lies in the ability to identify when the outcomes of our decisions have something to teach us and what that lesson might be.</div></li><li><div><strong>As outcomes come our way, figuring out whether those outcomes were caused mainly by luck or whether they were the predictable result of particular decisions we made is a bet of great consequence.</strong></div></li><li><div>We have the opportunity to learn from the way the future unfolds to improve our beliefs and decisions going forward. The more evidence we get from experience, the less uncertainty we have about our beliefs and choices. Actively using outcomes to examine our beliefs and bets closes the feedback loop, reducing uncertainty.</div></li><li><div><strong>Ideally, our beliefs and our bets improve with time as we learn from experience.</strong></div></li><li><div><strong>Ideally, the more information we have, the better we get at making decisions about which possible future to bet on.</strong></div></li><li><div>Ideally, as we learn from experience we get better at assessing the likelihood of a particular outcome given any decision, making our predictions about the future more accurate.</div></li><li><div>We are good at identifying the “-ER” goals we want to pursue (better, smarter, richer, healthier, whatever). But we fall short in achieving our “-ER” because of the difficulty in executing all the little decisions along the way to our goals.</div></li></ul><li><div>Luck vs. skill: fielding outcomes</div></li><ul><li><div><strong>The way our lives turn out is the result of two things: the influence of skill and the influence of luck.</strong></div></li><li><div>If making the same decision again would predictably result in the same outcome, or if changing the decision would predictably result in a different outcome, then the outcome following that decision was due to skill.</div></li><li><div>If our decisions didn’t have much impact on the way things turned out, then luck would be the main influence.</div></li><li><div>We make similar bets about where to “throw” an outcome: into the “skill bucket” (in our control) or the “luck bucket” (outside of our control). This initial fielding of outcomes, if done well, allows us to focus on experiences that have something to teach us (skill) and ignore those that don’t (luck).</div></li></ul><li><div>Working backward is hard: the SnackWell’s Phenomenon</div></li><ul><li><div><strong>The introduction of uncertainty drastically slows learning.</strong><br></div></li><li><div>When we field our outcomes as the future unfolds, we always run into this problem: the way things turn out could be the result of our decisions, luck, or some combination of the two. Just as we are almost never 100% wrong or right, outcomes are almost never 100% due to luck or skill.<br></div></li></ul><li><div>“If it weren’t for luck, I’d win every one”<br></div></li><ul><li><div>The way we field outcomes is predictably patterned: <strong>we take credit for the good stuff and blame the bad stuff on luck so it won’t be our fault. The result is that we don’t learn from experience well.</strong></div></li><ul><li><div><strong>“Self-serving bias”</strong> is the term for this pattern of fielding outcomes.</div></li></ul></ul></ul><ul><ul><li><div><strong>Blaming the bulk of our bad outcomes on luck means we miss opportunities to examine our decisions to see where we can do better.</strong> Taking credit for the good stuff means we will often reinforce decisions that shouldn’t be reinforced and miss opportunities to see where we could have done better.<br></div></li></ul><li><div>All-or-nothing thinking rears its head again<br></div></li><ul><li><div>Black-and-white thinking, uncolored by the reality of uncertainty, is a driver of both motivated reasoning and self-serving bias.<br></div></li><li><div>We ignore or discredit the information to hold steadfast in our belief.<br></div></li><li><div>Fielding outcomes with the goal of promoting our self-narrative and doing it in an all-or-nothing fashion alters our ability to make smart bets about why the future unfolded in a particular way.<br></div></li><li><div>When it comes to self-serving bias, we act as if our good outcomes are perfectly correlated to good skill and our bad outcomes are perfectly correlated to bad luck.*<br></div></li></ul><li><div>People watching<br></div></li><ul><li><div>Watching is an established learning method.<br></div></li><li><div><strong>We field the outcomes of our peers predictably.</strong><br></div></li><li><div>Where we blame our own bad outcomes on bad luck, when it comes to our peers, bad outcomes are clearly their fault. While our own good outcomes are due to our awesome decision-making, when it comes to other people, good outcomes are because they got lucky.<br></div></li></ul><li><div>Other people’s outcomes reflect on us<br></div></li><ul><li><div><strong>Just as with motivated reasoning and self-serving bias, blaming others for their bad results and failing to give them credit for their good ones is under the influence of ego.</strong><br></div></li><li><div>That’s schadenfreude: deriving pleasure from someone else’s misfortune. Schadenfreude is basically the opposite of compassion.</div></li><li><div><strong>Ideally, our happiness would depend on how things turn out for us regardless of how things turn out for anyone else.</strong></div></li><li><div>Our genes are competitive. As Richard Dawkins points out, natural selection proceeds by competition among the phenotypes of genes so we literally evolved to compete, a drive that allowed our species to survive. Engaging the world through the lens of competition is deeply embedded in our animal brains.</div></li><li><div>What accounts for most of the variance in happiness is how we’re doing comparatively.</div></li><li><div><strong>A lot of the way we feel about ourselves comes from how we think we compare with others. This robust and pervasive habit of mind impedes learning.</strong></div></li><li><div>We can learn better and be more open-minded if we work toward a positive narrative driven by engagement in truthseeking and striving toward accuracy and objectivity: giving others credit when it’s due, admitting when our decisions could have been better, and acknowledging that almost nothing is black and white.</div></li></ul><li><div>Reshaping habit</div></li><ul><li><div>Habits operate in a neurological loop consisting of three parts: the cue, the routine, and the reward.</div></li><li><div>The best way to deal with a habit is to respect the habit loop: <strong>“To change a habit, you must keep the old cue, and deliver the old reward, but insert a new routine.”</strong></div></li><li><div><strong>Our brain is built to seek positive self-image updates.</strong> It is also built to view ourselves in competition with our peers. We can’t install new hardware. Working with the way our brains are built in reshaping habit has a higher chance of success than working against it.</div></li><li><div>We can work to get the reward of feeling good about ourselves from being a good credit-giver, a good mistake-admitter, a good finder-of-mistakes-in-good-outcomes, a good learner, and (as a result) a good decision-maker.</div></li><li><div>Keep the reward of feeling like we are doing well compared to our peers, but change the features by which we compare ourselves: be a better credit-giver than your peers, more willing than others to admit mistakes, more willing to explore possible reasons for an outcome with an open mind, even, and especially, if that might cast you in a bad light or shine a good light on someone else.</div></li></ul><li><div>“Wanna bet?” redux</div></li><ul><li><div>If someone challenged us to a meaningful bet on how we fielded an outcome, we would find ourselves quickly moving beyond self-serving bias. If we wanted to win that bet, we wouldn’t reflexively field bad outcomes as all luck or good ones as all skill.</div></li><li><div><strong>The key is that in explicitly recognizing that the way we field an outcome is a bet, we consider a greater number of alternative causes more seriously than we otherwise would have. That is truthseeking.</strong></div></li><li><div>Betting on what we believe makes us take a closer look by making explicit what is already implicit: we have a great deal at risk in assessing why anything turned out the way it did.</div></li><li><div><strong>Thinking in bets triggers a more open-minded exploration of alternative hypotheses, of reasons supporting conclusions opposite to the routine of self-serving bias. </strong>We are more likely to explore the opposite side of an argument more often and more seriously—and that will move us closer to the truth of the matter.</div></li><li><div><strong>Thinking in bets also triggers perspective taking, leveraging the difference between how we field our own outcomes versus others’ outcomes to get closer to the objective truth.</strong></div></li><li><div>Perspective taking gets us closer to the truth because that truth generally lies in the middle of the way we field outcomes for ourselves and the way we field them for others. By taking someone else’s perspective, we are more likely to land in that middle ground.</div></li><li><div>Treating outcome fielding as bets constantly reminds us outcomes are rarely attributable to a single cause and there is almost always uncertainty in figuring out the various causes.</div></li><li><div>Identifying a negative outcome doesn’t have the same personal sting if you turn it into a positive by finding things to learn from it.</div></li></ul><li><div>The hard way</div></li><ul><li><div><strong>The benefits of recognizing just a few extra learning opportunities compound over time.</strong> The cumulative effect of being a little better at decision-making, like compounding interest, can have huge effects in the long run on everything that we do.</div></li><li><div>When we catch that extra occasional learning opportunity, it puts us in a better position for future opportunities of the same type.</div></li><li><div><strong>Any improvement in our decision quality puts us in a better position in the future.</strong></div></li></ul></ul><li><div>CHAPTER 4: The Buddy System</div></li><ul><li><div>“Maybe you’re the problem, do you think?”</div></li><ul><li><div><strong>Not all situations are appropriate for truthseeking, nor are all people interested in the pursuit.</strong></div></li></ul><li><div>The red pill or the blue pill?</div></li><ul><li><div>I had to learn to focus on the things I could control (my own decisions), let go of the things I couldn’t (luck), and work to be able to accurately tell the difference between the two.</div></li><li><div>Having the help of others provides many decision-making benefits, but one of the most obvious is that other people can spot our errors better than we can. We can help others in our pod overcome their blind-spot bias and they can help us overcome the same.</div></li><ul><li><div>In fact, as long as there are three people in the group (two to disagree and one to referee*), the truthseeking group can be stable and productive.</div></li></ul></ul><li><div>Not all groups are created equal</div></li><ul><li><div><strong>“Whereas confirmatory thought involves a one-sided attempt to rationalize a particular point of view, exploratory thought involves even-handed consideration of alternative points of view.”</strong></div></li><li><div><strong>Confirmatory thought amplifies bias, promoting and encouraging motivated reasoning because its main purpose is justification.</strong> Confirmatory thought promotes a love and celebration of one’s own beliefs, distorting how the group processes information and works through decisions, the result of which can be groupthink.</div></li><li><div><strong>Exploratory thought, on the other hand, encourages an open-minded and objective consideration of alternative hypotheses and a tolerance of dissent to combat bias.</strong> Exploratory thought helps the members of a group reason toward a more accurate representation of the world.</div></li><li><div>“Complex and open-minded thought is most likely to be activated when decision makers learn prior to forming any opinions that they will be accountable to an audience (a) whose views are unknown, (b) who is interested in accuracy, (c) who is reasonably well-informed, and (d) who has a legitimate reason for inquiring into the reasons behind participants’ judgments/choices.”</div></li><li><div><strong>Groups can improve the thinking of individual decision-makers when the individuals are accountable to a group whose interest is in accuracy.</strong></div></li><li><div>In addition to accountability and an interest in accuracy, the charter should also encourage and celebrate a diversity of perspectives to challenge biased thinking by individual members.</div></li><li><div>A pretty good blueprint for a truthseeking charter:</div></li><ul><li><div><strong>A focus on accuracy (over confirmation)</strong>, which includes rewarding truthseeking, objectivity, and open-mindedness within the group;</div></li><li><div><strong>Accountability</strong>, for which members have advance notice; and</div></li><li><div><strong>Openness to a diversity of ideas</strong>.</div></li></ul><li><div><strong>We don’t win bets by being in love with our own ideas.</strong> We win bets by relentlessly striving to calibrate our beliefs and predictions about the future to more accurately represent the world.</div></li><li><div><strong>In the long run, the more objective person will win against the more biased person.</strong> In that way, betting is a form of accountability to accuracy.</div></li><li><div>Calibration requires an open-minded consideration of diverse points of view and alternative hypotheses.</div></li><li><div>Even better, interacting with similarly motivated people improves the ability to combat bias not just during direct interactions but when we are making and analyzing decisions on our own. The group gets into our head—in a good way—reshaping our decision habits.</div></li></ul><li><div>The group rewards focus on accuracy</div></li><ul><li><div>While I never got close to attaining the goal of a pure focus on accuracy, my group helped me to give a little more credit than I otherwise would have, to spot a few more mistakes than I would have spotted on my own, to be more open-minded to strategic choices that I disagreed with.</div></li></ul><li><div>“One Hundred White Castles&nbsp;.&nbsp;.&nbsp;. and a large chocolate shake”: how accountability improves decision-making</div></li><ul><li><div><strong>Accountability is a willingness or obligation to answer for our actions or beliefs to others.</strong> A bet is a form of accountability. If we’re in love with our own opinions, it can cost us in a bet.</div></li><li><div>Being in an environment where the challenge of a bet is always looming works to reduce motivated reasoning. Such an environment changes the frame through which we view disconfirming information, reinforcing the frame change that our truthseeking group rewards.</div></li><li><div>Accountability, like reinforcement of accuracy, also improves our decision-making and information processing when we are away from the group because we know in advance that we will have to answer to the group for our decisions.</div></li></ul><li><div>The group ideally exposes us to a diversity of viewpoints</div></li><ul><li><div><strong>Diversity and dissent are not only checks on fallibility, but the only means of testing the ultimate truth of an opinion</strong>: “The only way in which a human being can make some approach to knowing the whole of a subject, is by hearing what can be said about it by persons of every variety of opinion, and studying all modes in which it can be looked at by every character of mind.</div></li><li><div>It is almost impossible for us, on our own, to get the diversity of viewpoints provided by the combined manpower of a well-formed decision pod. <strong>To get a more objective view of the world, we need an environment that exposes us to alternate hypotheses and different perspectives.</strong></div></li><li><div>To view ourselves in a more realistic way, we need other people to fill in our blind spots.</div></li><li><div>When we think in bets, we run through a series of questions to examine the accuracy of our beliefs. For example:</div></li><ul><li><div>Why might my belief not be true?</div></li><li><div>What other evidence might be out there bearing on my belief?</div></li><li><div>Are there similar areas I can look toward to gauge whether similar beliefs to mine are true?</div></li><li><div>What sources of information could I have missed or minimized on the way to reaching my belief?</div></li><li><div>What are the reasons someone else could have a different belief, what’s their support, and why might they be right instead of me?</div></li><li><div>What other perspectives are there as to why things turned out the way they did?</div></li></ul><li><div>It is a lot easier to have someone else offer their perspective than for you to imagine you’re another person and think about what their perspective might be. A diverse group can do some of the heavy lifting of de-biasing for us.</div></li></ul><li><div>Federal judges: drift happens</div></li><ul><li><div>This polarization warns against forming a decision group that is a collection of clones who share the same opinions and knowledge sources we do. The more homogeneous we get, the more the group will promote and amplify confirmatory thought.</div></li><li><div>In political discourse, virtually everyone, even those familiar with groupthink, will assert, “I’m in the rational group exchanging ideas and thinking these things through. The people on the other side, though, are in an echo chamber.”</div></li></ul><li><div>Social psychologists: confirmatory drift and Heterodox Academy</div></li><ul><li><div>The Heterodox Academy effort shows that there is a natural drift toward homogeneity and confirmatory thought. We all experience this gravitation toward people who think like we do.</div></li><li><div><strong>Groups with diverse viewpoints are the best protection against confirmatory thought.</strong> Peer review, the gold standard that epitomizes the open-mindedness and hypothesis testing of the scientific method, “offers much less protection against error when the community of peers is politically homogeneous.”</div></li><li><div>Experimental studies cited in the BBS paper found that confirmation bias led reviewers “to work extra hard to find flaws with papers whose conclusions they dislike, and to be more permissive about methodological issues when they endorse the conclusions.”</div></li></ul><li><div>Wanna bet (on science)?</div></li><ul><li><div>Experts engaging in traditional peer review, providing their opinion on whether an experimental result would replicate, were right 58% of the time. A betting market in which the traders were the exact same experts and those experts had money on the line predicted correctly 71% of the time.</div></li><li><div><strong>Expert opinion expressed as a bet was more accurate than expert opinion expressed through peer review.</strong></div></li><li><div>we know that scientists, like judges—and like us—are human and subject to these patterns of confirmatory thought. Making the risk explicit rather than implicit refocuses us all to be more objective.</div></li><li><div><strong>People are more willing to offer their opinion when the goal is to win a bet rather than get along with people in a room.</strong></div></li></ul></ul><li><div>CHAPTER 5: Dissent to Win</div></li><ul><li><div>CUDOS to a magician</div></li><ul><li><div>CUDOS stands for</div></li><ul><li><div><strong>Communism</strong> (data belong to the group),</div></li><li><div><strong>Universalism</strong> (apply uniform standards to claims and evidence, regardless of where they came from),</div></li><li><div><strong>Disinterestedness</strong> (vigilance against potential conflicts that can influence the group’s evaluation), and</div></li><li><div><strong>Organized Skepticism</strong> (discussion among the group to encourage engagement and dissent).</div></li></ul><li><div>Each element of CUDOS—communism, universalism, disinterestedness, and organized skepticism—can be broadly applied and adapted to push a group toward objectivity.</div></li></ul><li><div>Mertonian communism: more is more</div></li><ul><li><div>Merton argued that, in academics, an individual researcher’s data must eventually be shared with the scientific community at large for knowledge to advance. “Secrecy is the antithesis of this norm; full and open communication its enactment.”</div></li><li><div>Any attempt at accuracy is bound to fall short if the truthseeking group has only limited access to potentially pertinent information. Without all the facts, accuracy suffers.</div></li><li><div><strong>if you’re doing an experiment, you should report everything that you think might make it invalid—not only what you think is right about it: other causes that could possibly explain your results&nbsp;.&nbsp;.&nbsp;.”</strong></div></li><li><div><strong>Within our own decision pod, we should strive to abide by the rule that “more is more.” Get all the information out there.</strong> Indulge the broadest definition of what could conceivably be relevant.</div></li><li><div>As a rule of thumb, if we have an urge to leave out a detail because it makes us uncomfortable or requires even more clarification to explain away, those are exactly the details we must share.</div></li><li><div>Sharing data and information, like the other elements of a truthseeking charter, is done by agreement.</div></li><li><div>Without an agreement, we can’t and shouldn’t compel others to share information they don’t want to share. We all have a right of privacy.</div></li><li><div>If the group is discussing a decision and it doesn’t have all the details, it might be because the person providing them doesn’t realize the relevance of some of the data. Or it could mean the person telling the story has a bias toward encouraging a certain narrative that they likely aren’t even aware of.</div></li><li><div><strong>We have all experienced situations where we get two accounts of the same event, but the versions are dramatically different because they are informed by different facts and perspectives. This is known as the Rashomon Effect.</strong></div></li><li><div><strong>The Rashomon Effect reminds us that we can’t assume one version of a story is accurate or complete.</strong> We can’t count on someone else to provide the other side of the story, or any individual’s version to provide a full and objective accounting of all the relevant information.</div></li><li><div>When presenting a decision for discussion, we should be mindful of details we might be omitting and be extra-safe by adding anything that could possibly be relevant. On the evaluation side, we must query each other to extract those details when necessary.</div></li><li><div>Be a data sharer. That’s what experts do. In fact, that’s one of the reasons experts become experts. They understand that sharing data is the best way to move toward accuracy because it extracts insight from your listeners of the highest fidelity.</div></li><li><div><strong>What the experts recognize is that the more detail you provide, the better the assessment of decision quality you get.</strong></div></li><li><div>If part of corporate success consists of providing the most accurate, objective, and detailed evaluation of what’s going on, employees will compete to win on those terms.</div></li></ul><li><div>Universalism: don’t shoot the message</div></li><ul><li><div>“Truth-claims, whatever their source, are to be subjected to preestablished impersonal criteria.” <strong>It means acceptance or rejection of an idea must not “depend on the personal or social attributes of their protagonist.”</strong></div></li><li><div>Another way to disentangle the message from the messenger is to imagine the message coming from a source we value much more or much less.</div></li><ul><li><div>“How would we feel about this if we heard it from a much different source?”</div></li></ul><li><div>John Stuart Mill made it clear that the only way to gain knowledge and approach truth is by examining every variety of opinion. We learn things we didn’t know. We calibrate better. Even when the result of that examination confirms our initial position, we understand that position better if we open ourselves to every side of the issue.</div></li></ul><li><div>Disinterestedness: we all have a conflict of interest, and it’s contagious</div></li><ul><li><div><strong>If those analyzing data knew, or could even just intuit, the hypothesis being tested, the analysis would be more likely to support the hypothesis being tested.</strong> The measurements might be objective, but slicing and dicing the data is vulnerable to bias, even unconsciously.</div></li><li><div><strong>Outcome blindness enforces disinterestedness.</strong></div></li><li><div>If the group is going to help us make and evaluate decisions in an unbiased way, we don’t want to infect them in the way the data analysts were infected if they could surmise the hypothesis being tested.</div></li><li><div><strong>If the outcome is known, it will bias the assessment of the decision quality to align with the outcome quality.</strong></div></li><li><div><strong>If the group is blind to the outcome, it produces higher fidelity evaluation of decision quality.</strong> The best way to do this is to deconstruct decisions before an outcome is known.</div></li><li><div>After the outcome, make it a habit when seeking advice to give the details without revealing the outcome.</div></li><li><div><strong>When trying to vet some piece of information, some fact or opinion, we would do well to shield our listeners from what our opinion is as we seek the group’s opinion.</strong></div></li><li><div>Simply put, the group is less likely to succumb to ideological conflicts of interest when they don’t know what the interest is.</div></li><li><div>Another way a group can de-bias members is to reward them for skill in debating opposing points of view and finding merit in opposing positions.</div></li><li><div>If two people disagree, a referee can get them to each argue the other’s position with the goal of being the best debater. This acts to shift the interest to open-mindedness to the opposing opinion rather than confirmation of their original position.</div></li></ul><li><div>Organized skepticism: real skeptics make arguments and friends</div></li><ul><li><div><strong>Skepticism is about approaching the world by asking why things might not be true rather than why they are true.</strong></div></li><li><div>Thinking in bets embodies skepticism by encouraging us to examine what we do and don’t know and what our level of confidence is in our beliefs and predictions.</div></li><li><div>we need to be particularly skeptical of information that agrees with us because we know that we are biased to just accept and applaud confirming evidence.</div></li><li><div>longer do we dissent with declarations of “You’re wrong!” Rather, we engage by saying, “I’m not sure about that.” Or even just ask, “Are you sure about that?” or “Have you considered this other way of thinking about it?”</div></li><li><div>Organized skepticism invites people into a cooperative exploration. People are more open to hearing differing perspectives expressed this way.</div></li></ul><li><div>Communicating with the world beyond our group</div></li><ul><li><div>Ways to communicate to maximize our ability to engage in a truthseeking way with anyone.</div></li><ul><li><div><strong>First, express uncertainty.</strong></div></li><ul><li><div>If we start by making clear our own uncertainty, our audience is more likely to understand that any discussion that follows will not involve right versus wrong, maximizing our truthseeking exchanges with those outside our chartered group.</div></li></ul><li><div><strong>Second, lead with assent.</strong></div></li><ul><li><div>For example, <strong>listen for the things you agree with, state those and be specific, and then follow with “and” instead of “but.”</strong> If there is one thing we have learned thus far it is that we like having our ideas affirmed. If we want to engage someone with whom we have some disagreement (inside or outside our group), they will be more open and less defensive if we start with those areas of agreement, which there surely will be.</div></li><li><div>When we lead with assent, our listeners will be more open to any dissent that might follow. In addition, when the new information is presented as supplementing rather than negating what has come before, our listeners will be much more open to what we have to say.</div></li><li><div>“And” is an offer to contribute. “But” is a denial and repudiation of what came before.</div></li><li><div>“Yes” means you are accepting the construct of the situation. “And” means you are adding to it. That’s an excellent guideline in any situation in which you want to encourage exploratory thought. The important thing is to try to find areas of agreement to maintain the spirit of partnership in seeking the truth.</div></li></ul><li><div><strong>Third, ask for a temporary agreement to engage in truthseeking.</strong> If someone is off-loading emotion to us, we can ask them if they are just looking to vent or if they are looking for advice.</div></li><ul><li><div>“Do you want to just let it all out, or are you thinking of what to do about it next?”</div></li><li><div>When we validate the other person’s experience of the past and refocus on exploration of the future, they can get to their past decisions on their own.</div></li></ul></ul></ul></ul><li><div>CHAPTER 6: Adventures in Mental Time Travel</div></li><ul><li><div>Let Marty McFly run into Marty McFly</div></li><ul><li><div>Away from the poker table, we don’t feel or experience the consequences of most of the decisions we make right away. If we are winning or losing to a particular decision, the consequences may take time to reveal themselves.</div></li><li><div>The best poker players develop practical ways to incorporate their long-term strategic goals into their in-the-moment decisions.</div></li><li><div><strong>Improving decision quality is about increasing our chances of good outcomes, not guaranteeing them.</strong></div></li><li><div><strong>Good results compound. Good processes become habits, and make possible future calibration and improvement.</strong></div></li></ul><li><div>Night Jerry</div></li><ul><li><div>This tendency we all have to favor our present-self at the expense of our future-self is called temporal discounting.* We are willing to take an irrationally large discount to get a reward now instead of waiting for a bigger reward later.</div></li><li><div><strong>When we think about the past and the future, we engage deliberative mind, improving our ability to make a more rational decision.</strong></div></li><li><div>Bringing our future-self into the decision gets us started thinking about the future consequences of those in-the-moment decisions.</div></li></ul><li><div>Moving regret in front of our decisions</div></li><ul><li><div>Philosophers agree that regret is one of the most intense emotions we feel, but they have argued about whether it is productive or useful.</div></li><li><div>The problem isn’t so much whether regret is an unproductive emotion. It’s that regret occurs after the fact, instead of before. As Nietzsche points out, regret can do nothing to change what has already happened.</div></li><li><div><strong>If regret occurred before a decision instead of after, the experience of regret might get us to change a choice likely to result in a bad outcome.</strong></div></li><li><div>We can interrupt an in-the-moment decision and take some time to consider the decision from the perspective of our past and future. We can then create a habit routine around these decision interrupts to encourage this perspective taking, asking ourselves a set of simple questions at the moment of the decision designed to get future-us and past-us involved. We can do this by imagining how future-us is likely to feel about the decision or by imagining how we might feel about the decision today if past-us had made it.</div></li><li><div>Suzy Welch developed a popular tool known as 10-10-10 that has the effect of bringing future-us into more of our in-the-moment decisions. <strong>“Every 10-10-10 process starts with a question.&nbsp;.&nbsp;.&nbsp;.</strong> <strong>What are the consequences of each of my options in ten minutes? In ten months? In ten years?”</strong></div></li><li><div>We can build on Welch’s tool by asking the questions through the frame of the past: <strong>“How would I feel today if I had made this decision ten minutes ago? Ten months ago? Ten years ago?”</strong></div></li><li><div>Moving regret in front of a decision has numerous benefits.</div></li><ul><li><div>First, obviously, it can influence us to make a better decision.</div></li><li><div>Second, it helps us treat ourselves (regardless of the actual decision) more compassionately after the fact. We can anticipate and prepare for negative outcomes.</div></li></ul></ul><li><div>A flat tire, the ticker, and a zoom lens</div></li><ul><li><div>In our decision-making lives, we aren’t that good at taking this kind of perspective—at accessing the past and future to get a better view of how any given moment might fit into the scope of time. It just feels how it feels in the moment and we react to it.</div></li><li><div><strong>Happiness (however we individually define it) is not best measured by looking at the ticker, zooming in and magnifying moment-by-moment or day-by-day movements. We would be better off thinking about our happiness as a long-term stock holding.</strong></div></li><li><div>The decisions driven by the emotions of the moment can become a self-fulfilling prophecy, degrading the quality of the bets we make, increasing the chances of bad outcomes, and making things worse.</div></li></ul><li><div>“Yeah, but what have you done for me lately?”</div></li><ul><li><div><strong>The way we field outcomes is path dependent. It doesn’t so much matter where we end up as how we got there. What has happened in the recent past drives our emotional response much more than how we are doing overall.</strong></div></li><li><div>Our in-the-moment emotions affect the quality of the decisions we make in those moments, and we are very willing to make decisions when we are not emotionally fit to do so.</div></li></ul><li><div>Tilt</div></li><ul><li><div>But for people involved in specialized activities, it’s worth it to be able to communicate a complex concept in a single word that laypeople would need lengthy phrases to convey. Having a nuanced, precise vocabulary is what jargon is all about.</div></li><li><div><strong>The concept that “bad outcomes can have an impact on your emotions that compromise your decision-making going forward so that you make emotionally charged, irrational decisions that are likely to result in more bad outcomes that will then negatively impact your decision-making going forward and so on.” The most common is tilt.</strong></div></li><li><div>Tilt is the poker player’s worst enemy, and the word instantly communicates to other poker players that you were emotionally unhinged in your decision-making because of the way things turned out.*</div></li><li><div>We can precommit to walk away from the situation when we feel the signs of tilt, whether it’s a fight with a spouse or child, aggravation in a work situation, or losing at a poker table. We can take some space till we calm down and get some perspective, recognizing that when we are on tilt we aren’t decision fit.</div></li><li><div>“Do you think maybe you are/were on tilt?”</div></li><li><div>“Do you think this will really matter in the long run?”</div></li><li><div>“It’s all just one long poker game.”</div></li><ul><li><div><strong>When we take the long view, we’re going to think in a more rational way.</strong></div></li></ul></ul><li><div>Ulysses contracts: time traveling to precommit</div></li><ul><li><div><strong>This action—past-us preventing present-us from doing something stupid—has become known as a Ulysses contract.</strong></div></li><li><div>A <strong>barrier-inducing Ulysses contract</strong> could involve us not going to the mall at all or budgeting our time tightly so we have just enough time to accomplish our intended purpose.</div></li><li><div>A <strong>barrier-reducing contract</strong> would be to precommit to carry healthy snacks in our bag, so we can increase the probability, if we’re doing any idle eating, that we can make a better choice since we have drastically reduced the effort it takes to grab a healthier snack.</div></li><li><div>Ulysses contracts can come in varying levels of how much your hands are bound, ranging from physically preventing acting on a decision to just committing in advance to certain actions without any barriers save the commitment itself. Regardless of the level of binding, precommitment contracts trigger a decision-interrupt. At the moment when we consider breaking the contract, when we want to cut the binding, we are much more likely to stop and think.</div></li></ul><li><div>Decision swear jar</div></li><ul><li><div>Signs of the illusion of certainty: other terms signaling that we’re presuming things are more certain than we know they are. This also includes stating things as absolutes, like “best” or “worst” and “always” or “never.”</div></li></ul></ul><ul><ul><li><div><strong>Overconfidence: similar terms to the illusion of certainty.</strong></div></li><li><div><strong>Irrational outcome fielding</strong>: “I can’t believe how unlucky I got,” or the reverse, if we have some default phrase for credit taking, like “I’m at the absolute top of my game” or “I planned it perfectly.” This includes conclusions of luck, skill, blame, or credit.</div></li><li><div><strong>Any kind of moaning or complaining about bad luck</strong> just to off-load it, with no real point to the story other than to get sympathy.</div></li><li><div><strong>Generalized characterizations of people meant to dismiss their ideas</strong>: insulting, pejorative characterizations of others, like “idiot” or, in poker, “donkey.”</div></li><li><div>Other violations of the Mertonian norm of universalism, <strong>shooting the message because we don’t think much of the messenger</strong>. Any sweeping term about someone, particularly when we equate our assessment of an idea with a sweeping personality or intellectual assessment of the person delivering the idea,</div></li><ul><li><div>Also be on guard for the reverse: accepting a message because of the messenger or praising a source immediately after finding out it confirms your thinking.</div></li></ul><li><div><strong>Signals that we have zoomed in on a moment, out of proportion with the scope of time</strong>: “worst day ever,” “the day from hell.”</div></li><li><div><strong>Expressions that explicitly signal motivated reasoning, accepting or rejecting information without much evidence</strong>, like “conventional wisdom” or “if you ask anybody”</div></li><li><div>Any words or thoughts denying the existence of uncertainty should be a signal that we are heading toward a poorly calibrated decision.</div></li><li><div><strong>Lack of self-compassion</strong>: if we’re going to be self-critical, the focus should be on the lesson and how to calibrate future decisions. “I have the worst judgment on relationships” or “I should have known” or “How could I be so stupid?”</div></li><li><div>Signals we’re being overly generous editors when we share a story. Especially in our truthseeking group, are we straying from sharing the facts to emphasize our version?</div></li><li><div><strong>Infecting our listeners with a conflict of interest</strong>, including our own conclusion or belief when asking for advice or informing the listener of the outcome before getting their input.</div></li><li><div>Terms that discourage engagement of others and their opinions, including expressions of certainty and also initial phrasing inconsistent with that great lesson from improvisation—“yes, and&nbsp;.&nbsp;.&nbsp;.” That includes getting opinions or information from others and starting with “no” or “but&nbsp;.&nbsp;.&nbsp;.”</div></li><li><div>Better precommitment contracts result from better anticipation of what the future might look like, what kinds of decisions we want to avoid, and which ones we want to promote.</div></li></ul><li><div>Reconnaissance: mapping the future</div></li><ul><li><div>We shouldn’t plan our future without doing advance work on the range of futures that could result from any given decision and the probabilities of those futures occurring.</div></li><li><div><strong>Any decision can result in a set of possible outcomes.</strong></div></li><li><div>Thinking about what futures are contained in that set (which we do by putting memories together in a novel way to imagine how things might turn out) helps us figure out which decisions to make.</div></li><li><div><strong>To start, we imagine the range of potential futures. This is also known as scenario planning.</strong></div></li><li><div><strong>After identifying as many of the possible outcomes as we can, we want to make our best guess at the probability of each of those futures occurring.</strong></div></li><ul><li><div>By at least trying to assign probabilities, we will naturally move away from the default of 0% or 100%, away from being sure it will turn out one way and not another. Anything that moves us off those extremes is going to be a more reasonable assessment than not trying at all.</div></li><li><div>Before making a bet, poker players consider each of their opponents’ possible responses (fold, call, raise), and the likelihood and desirability of each. They also think about what they will do in response (if some or all of the opponents don’t fold). Even if you don’t know much about poker, it should make sense that a player is better off considering these things before they bet. The more expert the player, the further into the future they plan.</div></li></ul><li><div>The best strategists are considering a fuller range of possible scenarios, anticipating and considering the strategic responses to each, and so on deep into the decision tree.</div></li><li><div><strong>Diverse viewpoints allow for the identification of a wider variety of scenarios deeper into the tree, and for better estimates of their probability.</strong></div></li><li><div>In addition to increasing decision quality, scouting various futures has numerous additional benefits.</div></li><ul><li><div>First, <strong>scenario planning reminds us that the future is inherently uncertain.</strong></div></li><li><div>Second, <strong>we are better prepared for how we are going to respond to different outcomes that might result from our initial decision.</strong></div></li><li><div>Third, <strong>anticipating the range of outcomes also keeps us from unproductive regret (or undeserved euphoria) when a particular future happens.</strong></div></li><li><div>Finally, <strong>by mapping out the potential futures and probabilities, we are less likely to fall prey to resulting or hindsight bias</strong>, in which we gloss over the futures that did not occur and behave as if the one that did occur must have been inevitable,</div></li></ul></ul><li><div>Scenario planning in practice</div></li><ul><li><div>Reconnaissance of the future dramatically improves decision quality and reduces reactivity to outcomes.</div></li></ul><li><div>Backcasting: working backward from a positive future</div></li><ul><li><div><strong>When it comes to advance thinking, standing at the end and looking backward is much more effective than looking forward from the beginning.</strong></div></li><li><div><strong>Remembering the future is a better way to plan for it.</strong></div></li><li><div>From the vantage point of the present, it’s hard to see past the next step. We end up over-planning for addressing problems we have right now. Implicit in that approach is the assumption that conditions will remain the same, facts won’t change, and the paradigm will remain stable. The world changes too fast to assume that approach is generally valid.</div></li><li><div>By working backward from the goal, we plan our decision tree in more depth, because we start at the end.</div></li><li><div>When we identify the goal and work backward from there to “remember” how we got there, the research shows that we do better.</div></li><li><div><strong>Prospective hindsight—imagining that an event has already occurred—increases the ability to correctly identify reasons for future outcomes by 30%.</strong></div></li><li><div>Backcasting makes it possible to identify when there are low-probability events that must occur to reach the goal. That could lead to developing strategies to increase the chances those events occur or to recognizing the goal is too ambitious.</div></li></ul><li><div>Premortems: working backward from a negative future</div></li><ul><li><div><strong>A premortem is an investigation into something awful, but before it happens.</strong></div></li><li><div>Backcasting and premortems complement each other. Backcasting imagines a positive future; a premortem imagines a negative future.</div></li><li><div>Despite the popular wisdom that we achieve success through positive visualization, it turns out that incorporating negative visualization makes us more likely to achieve our goals.</div></li><li><div><strong>People who imagine obstacles in the way of reaching their goals are more likely to achieve success, a process she has called “mental contrasting.”</strong></div></li><li><div><strong>We need to have positive goals, but we are more likely to execute on those goals if we think about the negative futures.</strong></div></li><li><div>We start a premortem by imagining why we failed to reach our goal.</div></li><li><div>Then we imagine why. All those reasons why we didn’t achieve our goal help us anticipate potential obstacles and improve our likelihood of succeeding.</div></li><li><div>Being a team player in a premortem isn’t about being the most enthusiastic cheerleader; it’s about being the most productive heckler.</div></li><li><div>The premortem starts with working backward from an unfavorable future, or failure to achieve a goal, so competing for favor, or feeling good about contributing to the process, is about coming up with the most creative, relevant, and actionable reasons for why things didn’t work out.</div></li><li><div>A planning process that includes a premortem creates a much healthier organization because it means that the people who do have dissenting opinions are represented in the planning.</div></li></ul><li><div>Dendrology and hindsight bias (or, Give the chainsaw a rest)</div></li><ul><li><div>Hindsight bias—the human tendency to believe that whatever happened was bound to happen, and that everyone must have known it.</div></li><li><div>By keeping an accurate representation of what could have happened (and not a version edited by hindsight), memorializing the scenario plans and decision trees we create through good planning process, we can be better calibrators going forward.</div></li><li><div>One of the things poker teaches is that we have to take satisfaction in assessing the probabilities of different outcomes given the decisions under consideration and in executing the bet we think is best.</div></li></ul></ul>
          </ul>
      </div>
    </div> <!-- /.container -->
  </body>
</html>
